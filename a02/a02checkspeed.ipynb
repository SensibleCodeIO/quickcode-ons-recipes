{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# messy imports to be tidied up later\n",
    "import xlutils, xypath\n",
    "import databaker\n",
    "import os\n",
    "import databaker.constants\n",
    "from databaker.constants import *\n",
    "import databaker.databakersolo as ds\n",
    "from databaker.jupybakeutils import HDim, savepreviewhtml, savepreviewhtmlBAGS, writetechnicalCSV, procrows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input-output\n",
    "inputfile = \"table-a02.xls\"\n",
    "outputfile = \"%s.csv\" % os.path.splitext(inputfile)[0]\n",
    "previewfile = \"preview.html\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading table-a02.xls which has size 1177600 bytes\n",
      "Table names: seasonally adjusted, not seasonally adjusted\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading %s which has size %d bytes\" % (inputfile, os.path.getsize(inputfile)))\n",
    "tableset = xypath.loader.table_set(inputfile, extension='xls')\n",
    "tabs = list(xypath.loader.get_sheets(tableset, \"*\"))\n",
    "print(\"Table names: %s\" % \", \".join([tab.name  for tab in tabs]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normal place for your recipe work\n",
    "conversionsegments = [ ]\n",
    "\n",
    "for tab in tabs:\n",
    "    obs = tab.filter(\"MGSL\").assert_one().shift(DOWN).fill(RIGHT).fill(DOWN).is_number().is_not_italic()\n",
    "    dimensions = [ \n",
    "        HDim(tab.col('A').one_of(['Male', 'Female', 'All Persons']), 'gender', CLOSEST, ABOVE), \n",
    "        HDim(tab.col('A').is_date(), TIME, DIRECTLY, LEFT), \n",
    "        HDim(tab.regex(\"All aged .*\"), 'ages', CLOSEST, UP), \n",
    "        HDim(tab.filter(\"Total economically active\").fill(LEFT).fill(RIGHT).is_not_blank(), 'indicator', DIRECTLY, ABOVE),\n",
    "        HDim(tab.name, 'adjusted_yn')\n",
    "    ]\n",
    "    conversionsegments.append((tab, dimensions, obs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file preview.html\n",
      "table 'seasonally adjusted' written\n",
      "javascript calculated\n"
     ]
    }
   ],
   "source": [
    "#savepreviewhtml(conversionsegments[0], previewfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting and writing 2 conversion segments into table-a02.csv\n",
      "conversion segment size 23480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goatchurch/sensiblecode/src/databaker/databaker/utils.py:47: UserWarning: Couldn't identify date 'blank'\n",
      "  warnings.warn(\"Couldn't identify date {!r}\".format(date))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion segment size 11288\n",
      "1.3161506652832031\n",
      "writing 2 conversion segments into table-a02.csv\n",
      "conversionwrite segment size 23480\n",
      "conversionwrite segment size 11288\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "print(\"converting and writing %d conversion segments into %s\" % (len(conversionsegments), outputfile))\n",
    "convertedrows = [ ]\n",
    "for conversionsegment in conversionsegments:\n",
    "    print(\"conversion segment size %d\" % len(conversionsegment[2]))\n",
    "    rows = procrows(conversionsegment)\n",
    "    convertedrows.append(rows)\n",
    "print(time.time() - t0)\n",
    "# Should detect errors and throw up preview with cells marked\n",
    "# (though actually the errors manifest further upstream, normally)\n",
    "    \n",
    "# here we can do further sorting and postprocessing and allocating to different files \n",
    "\n",
    "writetechnicalCSV(outputfile, conversionsegments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
