{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xlutils, xypath\n",
    "import databaker\n",
    "import databaker.constants\n",
    "from databaker.constants import *\n",
    "import databaker.databakersolo as ds\n",
    "from databaker.jupybakeutils import savepreviewhtml, writetechnicalCSV, procrows, TechnicalCSV, yield_dimension_values \n",
    "from databaker.jupybakeutils import savepreviewhtmlBAGS, HDim\n",
    "Dcelllookup = ds.overrides.Dcelllookup\n",
    "batchcelllookup = ds.overrides.batchcelllookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tablep1zips/2015-2015provisionaltablep1.zip',\n",
       "  'PROV - Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2015.xls',\n",
       "  'PROV - Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2015 CV.xls'),\n",
       " ('tablep1zips/2014-2014revisedtablep1.zip',\n",
       "  'REVISED - Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2014.xls',\n",
       "  'REVISED - Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2014 CV.xls'),\n",
       " ('tablep1zips/2013revised-2013-revised-table-p1.zip',\n",
       "  'REVISED - Pension Provision by Earnings & Age Group new Table P1.1a   Pension Type 2013.xls',\n",
       "  'REVISED - Pension Provision by Earnings & Age Group new Table P1.1b   Pension Type 2013 CV.xls'),\n",
       " ('tablep1zips/2012revised-2012-revised-table-p1.zip',\n",
       "  'REVISED - Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2012.xls',\n",
       "  'REVISED - Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2012 CV.xls'),\n",
       " ('tablep1zips/2011revisedsoc2010-2011-revised-table-p1--soc-2010-.zip',\n",
       "  'REVISED - Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2011.xls',\n",
       "  'REVISED - Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2011 CV.xls'),\n",
       " ('tablep1zips/2011provisionalsoc2000-2011-provisional-table-p1.zip',\n",
       "  'PROV - Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2011.xls',\n",
       "  'PROV - Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2011 CV.xls'),\n",
       " ('tablep1zips/2010revised-2010-revised-table-p1.zip',\n",
       "  'REVISED - Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2010.xls',\n",
       "  'REVISED - Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2010 CV.xls'),\n",
       " ('tablep1zips/2009-2009-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2009.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2009 CV.xls'),\n",
       " ('tablep1zips/2008-2008-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2008.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2008 CV.xls'),\n",
       " ('tablep1zips/2007-2007-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2007.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2007 CV.xls'),\n",
       " ('tablep1zips/2006-2006-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2006.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2006 CV.xls'),\n",
       " ('tablep1zips/2005-2005-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pension Type 2005.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pension Type 2005 CV.xls'),\n",
       " ('tablep1zips/2004-2004-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pensions Backseries 2004.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pensions Backseries 2004 CV.xls'),\n",
       " ('tablep1zips/2003-2003-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pensions Backseries 2003.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pensions Backseries 2003 CV.xls'),\n",
       " ('tablep1zips/2002-2002-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pensions Backseries 2002.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pensions Backseries 2002 CV.xls'),\n",
       " ('tablep1zips/2001-2001-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pensions Backseries 2001.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pensions Backseries 2001 CV.xls'),\n",
       " ('tablep1zips/2000-2000-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pensions Backseries 2000.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pensions Backseries 2000 CV.xls'),\n",
       " ('tablep1zips/1999-1999-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pensions Backseries 1999.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pensions Backseries 1999 CV.xls'),\n",
       " ('tablep1zips/1998-1998-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pensions Backseries 1998.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pensions Backseries 1998 CV.xls'),\n",
       " ('tablep1zips/1997-1997-table-p1.zip',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1a   Pensions Backseries 1997.xls',\n",
       "  'Pension Provision by Earnings & Age Group Table P1.1b   Pensions Backseries 1997 CV.xls')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile, io, re, os\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "dirname = \"tablep1zips\"\n",
    "dfiles = os.listdir(dirname)\n",
    "dfiles.sort(reverse=True)\n",
    "previewfile = \"preview.html\"\n",
    "\n",
    "# each zip file has name and CV version\n",
    "zipfilefile = [ ] # [ (zipfile, main, CV) ]\n",
    "for dfile in dfiles:\n",
    "    zfile = os.path.join(dirname, dfile)\n",
    "    zdir = zipfile.ZipFile(zfile)\n",
    "    zff = zdir.namelist()\n",
    "    zff = [z  for z in zff  if z[-4:] == \".xls\"]   # strip out docx versions\n",
    "    zff.sort()\n",
    "    assert len(zff) == 2, zff\n",
    "    zmain, zcv = zff\n",
    "    assert zcv[-7:] == \" CV.xls\", zff\n",
    "    assert zcv[:-7].replace(\"a\", \"b\") == zmain[:-4].replace(\"a\", \"b\"), zff\n",
    "    zipfilefile.append((zfile, zmain, zcv))\n",
    "        \n",
    "zipfilefile\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tablep1zips/2015-2015provisionaltablep1.zip {'Female', 'Notes', 'All', 'Glossary', 'Male'} {'Female', 'Notes', 'All', 'Glossary', 'Male'}\n",
      "tablep1zips/2014-2014revisedtablep1.zip {'Female', 'Notes', 'All', 'Glossary', 'Male'} {'Female', 'Notes', 'All', 'Glossary', 'Male'}\n",
      "tablep1zips/2013revised-2013-revised-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2012revised-2012-revised-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2011revisedsoc2010-2011-revised-table-p1--soc-2010-.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2011provisionalsoc2000-2011-provisional-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2010revised-2010-revised-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2009-2009-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2008-2008-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2007-2007-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2006-2006-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2005-2005-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2004-2004-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2003-2003-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2002-2002-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2001-2001-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/2000-2000-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/1999-1999-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/1998-1998-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n",
      "tablep1zips/1997-1997-table-p1.zip {'Female', 'All', 'Male'} {'Female', 'All', 'Male'}\n"
     ]
    }
   ],
   "source": [
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "def tablesetfromzip(zfile, fname):\n",
    "    zdir = zipfile.ZipFile(zfile)\n",
    "    z = zdir.read(zmain)\n",
    "    tf = NamedTemporaryFile(\"w+b\", suffix=\".xls\")\n",
    "    tf.write(z)\n",
    "    return xypath.loader.table_set(tf.name, extension='xls')\n",
    "\n",
    "# Now go through all and get the sheets for each of these (wastefully discarding after loading)\n",
    "for zfile, zmain, zcv in zipfilefile:\n",
    "    tablesetmain = tablesetfromzip(zfile, zmain)\n",
    "    tablesetcv = tablesetfromzip(zfile, zcv)\n",
    "    print(zfile, tablesetmain.names,tablesetcv.names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take one table from this list\n",
    "zfile, zmain, zcv = zipfilefile[0]\n",
    "tablesetmain = tablesetfromzip(zfile, zmain)\n",
    "tabs = list(xypath.loader.get_sheets(tablesetmain, \"All\"))\n",
    "tab = tabs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file preview.html\n",
      "table 'All' written\n"
     ]
    }
   ],
   "source": [
    "previewfile = \"preview.html\"\n",
    "savepreviewhtmlBAGS(tab, previewfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anchor = tab.is_bold().filter(contains_string('Description')).assert_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file preview.html\n",
      "table 'All' written\n"
     ]
    }
   ],
   "source": [
    "cat1 = anchor.fill(DOWN)\n",
    "cat2 = cat1.is_bold()\n",
    "savepreviewhtmlBAGS([cat1, cat2], previewfile)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file preview.html\n",
      "table 'All' written\n",
      "javascript calculated\n"
     ]
    }
   ],
   "source": [
    "dim1 = HDim(cat1, \"cat1\", DIRECTLY, LEFT)\n",
    "dim2 = HDim(cat2, \"cat2\", CLOSEST, UP)\n",
    "\n",
    "# apply the over-rides into the dimension !!!!!!!!\n",
    "for c in dim1.hbagset:\n",
    "    if c.is_bold():\n",
    "        dim1.cellvalueoverride[c._cell] = \"All\"\n",
    "\n",
    "dimensions = [ \n",
    "        dim2, dim1, \n",
    "                ]\n",
    "obs = anchor.fill(RIGHT).fill(DOWN).is_number()\n",
    "\n",
    "conversionsegment = (tab, dimensions, obs)\n",
    "savepreviewhtml(conversionsegment, batchcelllookup, previewfile)\n",
    "conversionsegments = [conversionsegment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<A7 'All employees'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = list(dim1.hbagset)[0]\n",
    "k._cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting and 1 conversion segments\n",
      "conversion segment size 903\n"
     ]
    }
   ],
   "source": [
    "outputfile = \"output.csv\"        \n",
    "print(\"converting and %d conversion segments\" % (len(conversionsegments)))\n",
    "convertedrows = [ ]\n",
    "for conversionsegment in conversionsegments:\n",
    "    print(\"conversion segment size %d\" % len(conversionsegment[2]))\n",
    "    rows = procrows(conversionsegment, batchcelllookup)\n",
    "    convertedrows.append(rows)\n",
    "    \n",
    "# Should detect errors and throw up preview with cells marked\n",
    "# (though actually the errors manifest further upstream, normally)\n",
    "    \n",
    "# here we can do further sorting and postprocessing and allocating to different files \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cat2': 'All employees', 'cat1': 'All', -9: 6510.0},\n",
       " {'cat2': 'All employees', 'cat1': '     Less than £100', -9: 69.0},\n",
       " {'cat2': 'All employees', 'cat1': '     £100 - £200', -9: 83.0},\n",
       " {'cat2': 'All employees', 'cat1': '     £200 - £300', -9: 1641.0},\n",
       " {'cat2': 'All employees', 'cat1': '     £400 - £500', -9: 171.0},\n",
       " {'cat2': 'All employees', 'cat1': '     £500 - £600', -9: 448.0},\n",
       " {'cat2': 'All employees', 'cat1': '     £600 and over', -9: 411.0},\n",
       " {'cat2': '16 - 21', 'cat1': '     Less than £100', -9: 8.0},\n",
       " {'cat2': '16 - 21', 'cat1': '     £200 - £300', -9: 3.5},\n",
       " {'cat2': '16 - 21', 'cat1': '     £400 - £500', -9: 66.0},\n",
       " {'cat2': '22 - 29', 'cat1': 'All', -9: 42.0},\n",
       " {'cat2': '22 - 29', 'cat1': '     £100 - £200', -9: 16.5},\n",
       " {'cat2': '22 - 29', 'cat1': '     £200 - £300', -9: 42.0},\n",
       " {'cat2': '22 - 29', 'cat1': '     £400 - £500', -9: 3.6},\n",
       " {'cat2': '22 - 29', 'cat1': '     £500 - £600', -9: 18.6},\n",
       " {'cat2': '22 - 29', 'cat1': '     £600 and over', -9: 0.9},\n",
       " {'cat2': '30 - 39', 'cat1': '     Less than £100', -9: 15.4},\n",
       " {'cat2': '30 - 39', 'cat1': '     £200 - £300', -9: 17.7},\n",
       " {'cat2': '30 - 39', 'cat1': '     £300 - £400', -9: 15.7},\n",
       " {'cat2': '30 - 39', 'cat1': '     £400 - £500', -9: 8.0},\n",
       " {'cat2': '30 - 39', 'cat1': '     £600 and over', -9: 670.0},\n",
       " {'cat2': '40 - 49', 'cat1': 'All', -9: 1095.0},\n",
       " {'cat2': '40 - 49', 'cat1': '     Less than £100', -9: 219.0},\n",
       " {'cat2': '40 - 49', 'cat1': '     £200 - £300', -9: 155.0},\n",
       " {'cat2': '40 - 49', 'cat1': '     £300 - £400', -9: 46.0},\n",
       " {'cat2': '40 - 49', 'cat1': '     £400 - £500', -9: 207.0},\n",
       " {'cat2': '40 - 49', 'cat1': '     £600 and over', -9: 415.0},\n",
       " {'cat2': '50 - 54', 'cat1': 'All', -9: 18.0},\n",
       " {'cat2': '50 - 54', 'cat1': '     £100 - £200', -9: 40.0},\n",
       " {'cat2': '50 - 54', 'cat1': '     £200 - £300', -9: 4.0},\n",
       " {'cat2': '50 - 54', 'cat1': '     £400 - £500', -9: 24.0},\n",
       " {'cat2': '50 - 54', 'cat1': '     £500 - £600', -9: 17.0},\n",
       " {'cat2': '55 - 59', 'cat1': 'All', -9: 778.0},\n",
       " {'cat2': '55 - 59', 'cat1': '     Less than £100', -9: 0.0},\n",
       " {'cat2': '55 - 59', 'cat1': '     £200 - £300', -9: 19.4},\n",
       " {'cat2': '55 - 59', 'cat1': '     £300 - £400', -9: 26.8},\n",
       " {'cat2': '55 - 59', 'cat1': '     £500 - £600', -9: 14.2},\n",
       " {'cat2': '55 - 59', 'cat1': '     £600 and over', -9: 13.1},\n",
       " {'cat2': '60 - 64', 'cat1': '     Less than £100', -9: 3.6},\n",
       " {'cat2': '60 - 64', 'cat1': '     £200 - £300', -9: 33.0},\n",
       " {'cat2': '60 - 64', 'cat1': '     £400 - £500', -9: 43.0},\n",
       " {'cat2': '60 - 64', 'cat1': '     £500 - £600', -9: 7.0},\n",
       " {'cat2': '65 AND OVER', 'cat1': 'All', -9: 29.0},\n",
       " {'cat2': '65 AND OVER', 'cat1': '     £100 - £200', -9: 2.7},\n",
       " {'cat2': '65 AND OVER', 'cat1': '     £400 - £500', -9: 11.8},\n",
       " {'cat2': '65 AND OVER', 'cat1': '     £600 and over', -9: 11.9}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = convertedrows[0]\n",
    "rows[::20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
